# MCG Criteria Extraction System Configuration

# Input/Output Paths
paths:
  input_pdf_dir: "uploads/mcg-guidelines"
  output_schema_dir: "data/output/schemas"
  temp_dir: "data/temp"
  logs_dir: "logs"

# PDF Extraction Settings
pdf_extraction:
  preserve_formatting: true
  extract_images: false
  page_range: null  # null = all pages, or specify [start, end]

# Structure Parser Settings
parser:
  section_headers:
    - "Clinical Indications for Admission to Inpatient Care"
    - "Alternatives to Admission"
    - "Optimal Recovery Course"
    - "Extended Stay"
    - "Discharge Planning"

# LLM Settings
llm:
  provider: "ollama"  # "google" or "ollama"
  
  # Ollama Settings (for local models)
  model: "qwen2.5:32b"  # Local Ollama model
  ollama_url: "http://localhost:11434"  # Ollama server URL
  
  # Ollama Performance Settings
  ollama_num_thread: 8  # CPU threads (adjust based on your CPU)
  ollama_num_ctx: 8192  # Context window size
  ollama_num_gpu: 1  # Use GPU if available (0 for CPU-only)
  
  # Google Gemini Settings (if using provider: "google")
  # model: "gemini-2.0-flash"  # Stable 2.0 Flash (free tier)
  # api_key_env_var: "GOOGLE_API_KEY"
  
  # Common Settings
  temperature: 0.1  # Low temperature for consistent extraction
  max_tokens: 8000
  timeout: 60
  retry_attempts: 3
  retry_delay: 2  # seconds

# Schema Builder Settings
schema:
  output_format: "json"
  validation_strict: true
  include_evidence_citations: true
  include_alternatives: true

# Medical Terminology Settings
terminology:
  use_snomed: true
  use_icd10: true
  use_loinc: true
  fallback_to_text: true  # If codes not found, use text descriptions

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file_output: true
  console_output: true
